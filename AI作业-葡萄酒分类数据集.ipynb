{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 葡萄酒分类数据集-数据处理Demo\n",
    "参考：https://blog.csdn.net/u012735708/article/details/84000262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression   #逻辑斯特回归，线性分类\n",
    "from sklearn.linear_model import SGDClassifier        #随机梯度参数估计\n",
    "from sklearn.svm import LinearSVC                     #支持向量机\n",
    "from sklearn.naive_bayes import MultinomialNB         #朴素贝叶斯\n",
    "from sklearn.neighbors import KNeighborsClassifier    #K近邻\n",
    "from sklearn.tree import DecisionTreeClassifier       #决策树\n",
    "from sklearn.ensemble import RandomForestClassifier   #随机森林\n",
    "from sklearn.ensemble import GradientBoostingClassifier   #梯度提升决策树\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    " \n",
    "from sklearn.preprocessing import MinMaxScaler   #最大最小归一化\n",
    "from sklearn.preprocessing import StandardScaler   #标准化\n",
    "from scipy.stats import pearsonr                    #皮尔森相关系数\n",
    "from sklearn.model_selection import train_test_split     #划分数据集\n",
    "from sklearn.model_selection import cross_val_score   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "#计算排列和组合数所需要的包\n",
    "from itertools import combinations\n",
    "from scipy.special import comb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、数据分析\n",
    "当我们拿到一批原始的数据，首先要明确基本信息。（利用pandas、matplotlib.pyplot、seaborn）  \n",
    "\n",
    "例如：样本数，特征维度，特征类型，各类别分布占比  \n",
    "- 看数据：data.shape、data.head()、train.describe()  \n",
    "- 看特征：data.info()、  \n",
    "- 看类别分布是否均衡：data['category'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns=['0Alcohol','1Malic acid ','2Ash','3Alcalinity of ash',\n",
    "         '4Magnesium','5Total phenols','6Flavanoid',\n",
    "         '7Nonflavanoid phenols','8Proanthocyanins ','9Color intensity ','10Hue ','11OD280/OD315 of diluted wines' ,'12Proline ','13category']\n",
    "data= pd.read_csv(\"wine.csv\",header=None,names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape \n",
    "\n",
    "# (178, 14) 一共178个样本，13个特征列，1个标签列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0Alcohol</th>\n",
       "      <th>1Malic acid</th>\n",
       "      <th>2Ash</th>\n",
       "      <th>3Alcalinity of ash</th>\n",
       "      <th>4Magnesium</th>\n",
       "      <th>5Total phenols</th>\n",
       "      <th>6Flavanoid</th>\n",
       "      <th>7Nonflavanoid phenols</th>\n",
       "      <th>8Proanthocyanins</th>\n",
       "      <th>9Color intensity</th>\n",
       "      <th>10Hue</th>\n",
       "      <th>11OD280/OD315 of diluted wines</th>\n",
       "      <th>12Proline</th>\n",
       "      <th>13category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0Alcohol  1Malic acid   2Ash  3Alcalinity of ash  4Magnesium  \\\n",
       "0     14.23          1.71  2.43                15.6         127   \n",
       "1     13.20          1.78  2.14                11.2         100   \n",
       "2     13.16          2.36  2.67                18.6         101   \n",
       "3     14.37          1.95  2.50                16.8         113   \n",
       "4     13.24          2.59  2.87                21.0         118   \n",
       "\n",
       "   5Total phenols  6Flavanoid  7Nonflavanoid phenols  8Proanthocyanins   \\\n",
       "0            2.80        3.06                   0.28               2.29   \n",
       "1            2.65        2.76                   0.26               1.28   \n",
       "2            2.80        3.24                   0.30               2.81   \n",
       "3            3.85        3.49                   0.24               2.18   \n",
       "4            2.80        2.69                   0.39               1.82   \n",
       "\n",
       "   9Color intensity   10Hue   11OD280/OD315 of diluted wines  12Proline   \\\n",
       "0               5.64    1.04                            3.92        1065   \n",
       "1               4.38    1.05                            3.40        1050   \n",
       "2               5.68    1.03                            3.17        1185   \n",
       "3               7.80    0.86                            3.45        1480   \n",
       "4               4.32    1.04                            2.93         735   \n",
       "\n",
       "   13category  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      "0Alcohol                          178 non-null float64\n",
      "1Malic acid                       178 non-null float64\n",
      "2Ash                              178 non-null float64\n",
      "3Alcalinity of ash                178 non-null float64\n",
      "4Magnesium                        178 non-null int64\n",
      "5Total phenols                    178 non-null float64\n",
      "6Flavanoid                        178 non-null float64\n",
      "7Nonflavanoid phenols             178 non-null float64\n",
      "8Proanthocyanins                  178 non-null float64\n",
      "9Color intensity                  178 non-null float64\n",
      "10Hue                             178 non-null float64\n",
      "11OD280/OD315 of diluted wines    178 non-null float64\n",
      "12Proline                         178 non-null int64\n",
      "13category                        178 non-null int64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info() #查看数据概述\n",
    "\n",
    "# 特征列类型：: float64(11), int64(2)\n",
    "# 标签列：int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0Alcohol                          float64\n",
       "1Malic acid                       float64\n",
       "2Ash                              float64\n",
       "3Alcalinity of ash                float64\n",
       "4Magnesium                          int64\n",
       "5Total phenols                    float64\n",
       "6Flavanoid                        float64\n",
       "7Nonflavanoid phenols             float64\n",
       "8Proanthocyanins                  float64\n",
       "9Color intensity                  float64\n",
       "10Hue                             float64\n",
       "11OD280/OD315 of diluted wines    float64\n",
       "12Proline                           int64\n",
       "13category                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes #查看数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0Alcohol</th>\n",
       "      <th>1Malic acid</th>\n",
       "      <th>2Ash</th>\n",
       "      <th>3Alcalinity of ash</th>\n",
       "      <th>4Magnesium</th>\n",
       "      <th>5Total phenols</th>\n",
       "      <th>6Flavanoid</th>\n",
       "      <th>7Nonflavanoid phenols</th>\n",
       "      <th>8Proanthocyanins</th>\n",
       "      <th>9Color intensity</th>\n",
       "      <th>10Hue</th>\n",
       "      <th>11OD280/OD315 of diluted wines</th>\n",
       "      <th>12Proline</th>\n",
       "      <th>13category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>1.938202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.775035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0Alcohol  1Malic acid         2Ash  3Alcalinity of ash  4Magnesium  \\\n",
       "count  178.000000    178.000000  178.000000          178.000000  178.000000   \n",
       "mean    13.000618      2.336348    2.366517           19.494944   99.741573   \n",
       "std      0.811827      1.117146    0.274344            3.339564   14.282484   \n",
       "min     11.030000      0.740000    1.360000           10.600000   70.000000   \n",
       "25%     12.362500      1.602500    2.210000           17.200000   88.000000   \n",
       "50%     13.050000      1.865000    2.360000           19.500000   98.000000   \n",
       "75%     13.677500      3.082500    2.557500           21.500000  107.000000   \n",
       "max     14.830000      5.800000    3.230000           30.000000  162.000000   \n",
       "\n",
       "       5Total phenols  6Flavanoid  7Nonflavanoid phenols  8Proanthocyanins   \\\n",
       "count      178.000000  178.000000             178.000000         178.000000   \n",
       "mean         2.295112    2.029270               0.361854           1.590899   \n",
       "std          0.625851    0.998859               0.124453           0.572359   \n",
       "min          0.980000    0.340000               0.130000           0.410000   \n",
       "25%          1.742500    1.205000               0.270000           1.250000   \n",
       "50%          2.355000    2.135000               0.340000           1.555000   \n",
       "75%          2.800000    2.875000               0.437500           1.950000   \n",
       "max          3.880000    5.080000               0.660000           3.580000   \n",
       "\n",
       "       9Color intensity       10Hue   11OD280/OD315 of diluted wines  \\\n",
       "count         178.000000  178.000000                      178.000000   \n",
       "mean            5.058090    0.957449                        2.611685   \n",
       "std             2.318286    0.228572                        0.709990   \n",
       "min             1.280000    0.480000                        1.270000   \n",
       "25%             3.220000    0.782500                        1.937500   \n",
       "50%             4.690000    0.965000                        2.780000   \n",
       "75%             6.200000    1.120000                        3.170000   \n",
       "max            13.000000    1.710000                        4.000000   \n",
       "\n",
       "        12Proline   13category  \n",
       "count   178.000000  178.000000  \n",
       "mean    746.893258    1.938202  \n",
       "std     314.907474    0.775035  \n",
       "min     278.000000    1.000000  \n",
       "25%     500.500000    1.000000  \n",
       "50%     673.500000    2.000000  \n",
       "75%     985.000000    3.000000  \n",
       "max    1680.000000    3.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() #查看数据概述\n",
    "\n",
    "# 可以得到：\n",
    "# 1、各特征没有缺失值\n",
    "# 2、数值型特征的量纲不同\n",
    "# 3、方差变化也很大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: 13category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['13category'].value_counts() #查看这一列的值统计\n",
    "\n",
    "# 3个类别，分别为59、71、48，样本较为均衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['13category'].unique() #查看数据取值有哪些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.corr() #相关系数矩阵，即给出了任意两款菜式之间的相关系数\n",
    "# 不过数据量很大时会很慢，所以特征维度高时就别用了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0Alcohol                          0\n",
       "1Malic acid                       0\n",
       "2Ash                              0\n",
       "3Alcalinity of ash                0\n",
       "4Magnesium                        0\n",
       "5Total phenols                    0\n",
       "6Flavanoid                        0\n",
       "7Nonflavanoid phenols             0\n",
       "8Proanthocyanins                  0\n",
       "9Color intensity                  0\n",
       "10Hue                             0\n",
       "11OD280/OD315 of diluted wines    0\n",
       "12Proline                         0\n",
       "13category                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()  #查看每一列缺失值情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "148    0\n",
       "149    0\n",
       "150    0\n",
       "151    0\n",
       "152    0\n",
       "153    0\n",
       "154    0\n",
       "155    0\n",
       "156    0\n",
       "157    0\n",
       "158    0\n",
       "159    0\n",
       "160    0\n",
       "161    0\n",
       "162    0\n",
       "163    0\n",
       "164    0\n",
       "165    0\n",
       "166    0\n",
       "167    0\n",
       "168    0\n",
       "169    0\n",
       "170    0\n",
       "171    0\n",
       "172    0\n",
       "173    0\n",
       "174    0\n",
       "175    0\n",
       "176    0\n",
       "177    0\n",
       "Length: 178, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum(axis=1) #查看每一行缺失值情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 截取特征和标签\n",
    "features = data.loc[:, '0Alcohol':'12Proline ']\n",
    "labels = data['13category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1） 数据类型分类处理转换  \n",
    "2） 缺失值处理  \n",
    "3） 异常值处理  \n",
    "4） 无量纲化（规范化）  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值统计与处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0Alcohol                          0\n",
       "1Malic acid                       0\n",
       "2Ash                              0\n",
       "3Alcalinity of ash                0\n",
       "4Magnesium                        0\n",
       "5Total phenols                    0\n",
       "6Flavanoid                        0\n",
       "7Nonflavanoid phenols             0\n",
       "8Proanthocyanins                  0\n",
       "9Color intensity                  0\n",
       "10Hue                             0\n",
       "11OD280/OD315 of diluted wines    0\n",
       "12Proline                         0\n",
       "13category                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 缺失数查看\n",
    "data.isnull().sum()  #查看每一列缺失值情况\n",
    "data.isnull().sum().sort_values(ascending=False)\n",
    "# 缺失值填充\n",
    "data = data.fillna(data.median()) \n",
    "# 根据每列进行填充\n",
    "for col in data.columns:\n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "\n",
    "# 统计缺失率超过90%的特征\n",
    "train = data\n",
    "isnull_cols = []\n",
    "feature_selected=[]\n",
    "for col in train.columns:\n",
    "    if train[col].isnull().sum()/train[col].count() >= 0.9:\n",
    "        isnull_cols.append(col)\n",
    "    else:\n",
    "        feature_selected.append(col)\n",
    "print('There exists ', len(isnull_cols), ' columns with much null value.')\n",
    "# 去除缺失率高的列\n",
    "data = data[feature_selected]\n",
    "\n",
    "\n",
    "# 统计缺失值超过90%的特征列,封装成函数\n",
    "# 把特征个数少的列全部丢弃,使用和不适用效果影响不大，建议使用，省时间内存\n",
    "def null_ratio(df):\n",
    "    features=df.columns\n",
    "    feature_selected=[]\n",
    "    drop_index=[]\n",
    "    sz=df.size\n",
    "    for feat in features:\n",
    "        sz_null=df[df[feat].isnull()].size\n",
    "        ratio=float(sz_null)/sz\n",
    "        if ratio > 0.9:\n",
    "            drop_index.append(feat) \n",
    "        else:\n",
    "            feature_selected.append((feat,ratio))\n",
    "    return feature_selected,drop_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据数据类型分别处理：\n",
    "1字符串特征：label编码  \n",
    "2数值特征：数据变换，基于多项式、指数函数、对数函数等  \n",
    "3低基数类别特征（定性特征）：哑编码 和 one-hot编码  \n",
    "4高基数类别特征：先降维，再编码  \n",
    "5定量特征：二值化  \n",
    "6时间特征：日期季度时间等划分（参考：https://blog.csdn.net/JR_lu/article/details/52987573?locationNum=3&fps=1）  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 连续特征离散化\n",
    "df['pv_bins']=pd.cut(df['item_pv_level'],bins=[0,5,10,15,20]).astype('str')\n",
    "df['pv_bins']=LabelEncoder().fit_transform(df['pv_bins'])\n",
    "\n",
    "# 2 连续特征二值化\n",
    "# 对定量特征二值化:设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0\n",
    "from sklearn.preprocessing import Binarizer\n",
    "# 参考一：\n",
    "df['item_pv_level']=Binarizer(threshold=10).fit_transform(df['item_pv_level'].values.reshape(-1,1))\n",
    "# 参考二：\n",
    "features_new = Binarizer(threshold=3).fit_transform(features)\n",
    "\n",
    "# 3 字符串特征label编码\n",
    "for feature in features.columns:\n",
    "    data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "\n",
    "# 4 类别特征哑编码\n",
    "# 参考一：\n",
    "# 若不是数值表示，先用LabelEncoder对离散特征编码，因为onehotencoder只能处理数值\n",
    "# 然后使用OneHotEncoder编码，生成稀疏表示的特征\n",
    "# 再使用sparse.hstack连接连续特征和稀疏特征\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "data[feature] = LabelEncoder().fit_transform(data[feature].values)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(data[feature].values.reshape(-1, 1))\n",
    "train_a=enc.transform(data[feature].values.reshape(-1, 1))\n",
    "data_new= sparse.hstack((data, train_a))\n",
    "\n",
    "# 参考二：用pd.get_dummies()实现，（直接生成的稠密矩阵，内存开销很大）\n",
    "# 将离散的特征属性派生为多列只有0和1的属性\n",
    "data=pd.get_dummies(df,columns=['user_gender_id'],dummy_na=True)\n",
    "# 封装成函数：\n",
    "def dumyuserfeature(train):\n",
    "    train_copy = train.copy()\n",
    "    for i ,col in enumerate(train.columns): # enumerate将其组成一个索引序列，利用它可以同时获得索引和值\n",
    "        cofe = len(train.groupby(col).count()) # 看看这一维度中有多少不相同的值\n",
    "        if cofe < 20: #10,15都一样\n",
    "            feikong = np.sum([train[col] != -999] )\n",
    "            if feikong < len(train) * 0.1:\n",
    "                continue\n",
    "            # join：将两个DataFrame中的不同的列索引合并成为一个DataFrame\n",
    "            # pd.get_dummies : 如果DataFrame的某一列中含有k个不同的值，则可以派生出一个k列矩阵或DataFrame（其值全为1和0）\n",
    "            train_copy = train_copy.join(pd.get_dummies(train[col], prefix=col+'_'))\n",
    "    return train_copy\n",
    "\n",
    "# 5 数据变换\n",
    "# 5.1 基于多项式变换（对行变量处理）\n",
    "features_new = preprocessing.PolynomialFeatures().fit_transform(features)\n",
    "# 5.2 基于自定义函数变换，以log函数为例\n",
    "features_new = preprocessing.FunctionTransformer(np.log1p).fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 规范化处理：（一般在划分数据集之后再标准化或归一化）\n",
    "（注意标准化和归一化的区别：标准化针对列，归一化针对行向量）  \n",
    "- 归一化是将每个样本的所有特征转换到同一量纲下，把所有特征数据映射到[0,1]或者[-1, 1]区间内  \n",
    "- 标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，转换为标准正态分布，和整体样本分布相关，每个样本点都能对标准化产生影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,Normalizer,StandardScaler\n",
    "scaler=StandardScaler() #0均值，单位方差\n",
    "scaler=MinMaxScaler(feature_range=(0, 1)) #变换到[0,1]区间（也可以是其他固定最小最大值的区间）\n",
    "scaler=Normalizer(norm='l2') # 'l1', 'l2', or 'max', optional ('l2' by default)\n",
    "\n",
    "# print(np.mean(features, axis=0))\n",
    "# print(np.std(features, axis=0))\n",
    "# 1.标准化：将服从正态分布的特征值转换成标准正态分布（对列向量处理）\n",
    "features_new = StandardScaler().fit_transform(features)\n",
    "# 2 区间缩放：将特征值缩放到[0, 1]区间的数据（对列向量处理）\n",
    "features_new = MinMaxScaler().fit_transform(features)\n",
    "    \n",
    "# 3 归一化：将行向量转化为“单位向量”（对每个样本处理）\n",
    "features_new = Normalizer().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 删除方差较小的列(方差较小的特征含有的信息较少,更多的是噪音)\n",
    "train_des = train.describe()\n",
    "low_variance_cols = []\n",
    "for col in train_des.columns:\n",
    "    if train_des.loc['std',col]< 1e-5:\n",
    "        low_variance_cols.append(col)\n",
    "print('There exists ', len(low_variance_cols), ' columns with low std.')\n",
    "\n",
    "# 存储\n",
    "train.to_csv('./data_deal/train_deal_1.csv',index = None)\n",
    "test.to_csv('./data_deal/test.csv',index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、划分数据集 + 模型\n",
    "\n",
    "若数据样本较好，可以先不做特征工程，直接带模型看看效果  \n",
    "若预处理后数据样本维度较大或相关性较强，就先做特征工程，再带模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1）训练集和测试集划分  \n",
    "2）LR模型  \n",
    "3）SVM模型  \n",
    "4）最近邻分类模型  \n",
    "5）决策树  \n",
    "6）随机森林  \n",
    "7）XGBoost  \n",
    "8）LightBGM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#划分训练集和测试集  \n",
    "X_train,X_test,y_train,y_test=train_test_split(features,labels,test_size=0.2,random_state=0) \n",
    "#此处采用最大最小归一化， 可以换成StandardScaler()归一化方法,如果用StandardScaler()方法的话，则不能使用MultinomialNB()模型\n",
    "ss=MinMaxScaler()\n",
    "#ss=StandardScaler()                           \n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "模型及模型参数：\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "模型准确率：\n",
      "0.972222222222\n",
      "==============================\n",
      "模型及模型参数：\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "模型准确率：\n",
      "1.0\n",
      "==============================\n",
      "模型及模型参数：\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "模型准确率：\n",
      "1.0\n",
      "==============================\n",
      "模型及模型参数：\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "模型准确率：\n",
      "0.944444444444\n",
      "==============================\n",
      "模型及模型参数：\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "模型准确率：\n",
      "0.972222222222\n",
      "==============================\n",
      "模型及模型参数：\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "模型准确率：\n",
      "0.972222222222\n",
      "==============================\n",
      "模型及模型参数：\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "模型准确率：\n",
      "0.972222222222\n",
      "==============================\n",
      "模型及模型参数：\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "模型准确率：\n",
      "0.944444444444\n",
      "==============================\n",
      "模型及模型参数：\n",
      "GaussianNB(priors=None)\n",
      "模型准确率：\n",
      "0.916666666667\n",
      "==============================\n",
      "模型及模型参数：\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "模型准确率：\n",
      "0.972222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#模型及模型参数列表\n",
    "clfs = [LogisticRegression(),SGDClassifier(),LinearSVC(),MultinomialNB(),KNeighborsClassifier(),\\\n",
    "        DecisionTreeClassifier(),RandomForestClassifier(),GradientBoostingClassifier(),GaussianNB(),ExtraTreesClassifier()]\n",
    "#输出模型及参数信息，以及模型分类准确性\n",
    "for model in clfs:\n",
    "        print(\"==============================\")\n",
    "        print(\"模型及模型参数：\")   \n",
    "        print(str(model))\n",
    "        model.fit(X_train,y_train)\n",
    "        print(\"模型准确率：\")\n",
    "        print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型及模型参数：\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "模型评估：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      0.94      0.97        16\n",
      "          3       0.86      1.00      0.92         6\n",
      "\n",
      "avg / total       0.98      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "cls=linear_model.LogisticRegression()\n",
    "cls.fit(X_train,y_train)\n",
    "y_pred=cls.predict(X_test)\n",
    "\n",
    "print(\"模型及模型参数：\")   \n",
    "print(str(cls))\n",
    "print(\"模型评估：\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型及模型参数：\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=10, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "模型评估：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.79      0.88        14\n",
      "          2       0.84      1.00      0.91        16\n",
      "          3       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.93      0.92      0.92        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\D(Program)\\AI\\Anaconda3-4.3.1\\lib\\site-packages\\sklearn\\svm\\base.py:220: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVM模型  \n",
    "from sklearn.svm import SVR,SVC\n",
    "\n",
    "cls=SVC(probability=True,kernel='rbf',C=0.1,max_iter=10)\n",
    "cls.fit(X_train,y_train)\n",
    "y_pred=cls.predict(X_test)\n",
    "\n",
    "print(\"模型及模型参数：\")   \n",
    "print(str(cls))\n",
    "print(\"模型评估：\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型及模型参数：\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "模型评估：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00        14\n",
      "          2       1.00      0.94      0.97        16\n",
      "          3       0.86      1.00      0.92         6\n",
      "\n",
      "avg / total       0.98      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K近邻分类模型  \n",
    "\n",
    "cls=KNeighborsClassifier()\n",
    "cls.fit(X_train,y_train)\n",
    "y_pred=cls.predict(X_test)\n",
    "\n",
    "print(\"模型及模型参数：\")   \n",
    "print(str(cls))\n",
    "print(\"模型评估：\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型及模型参数：\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "模型评估：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.93      1.00      0.97        14\n",
      "          2       1.00      0.94      0.97        16\n",
      "          3       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 决策树  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cls=DecisionTreeClassifier()\n",
    "cls.fit(X_train,y_train)\n",
    "y_pred=cls.predict(X_test)\n",
    "\n",
    "print(\"模型及模型参数：\")   \n",
    "print(str(cls))\n",
    "print(\"模型评估：\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型及模型参数：\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "模型评估：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.93      1.00      0.97        14\n",
      "          2       1.00      0.94      0.97        16\n",
      "          3       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cls=RandomForestClassifier()\n",
    "cls.fit(X_train,y_train)\n",
    "y_pred=cls.predict(X_test)\n",
    "\n",
    "print(\"模型及模型参数：\")   \n",
    "print(str(cls))\n",
    "print(\"模型评估：\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型及模型参数：\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "模型评估：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.93      1.00      0.97        14\n",
      "          2       1.00      0.88      0.93        16\n",
      "          3       0.86      1.00      0.92         6\n",
      "\n",
      "avg / total       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "cls=GradientBoostingClassifier()\n",
    "cls.fit(X_train,y_train)\n",
    "y_pred=cls.predict(X_test)\n",
    "\n",
    "print(\"模型及模型参数：\")   \n",
    "print(str(cls))\n",
    "print(\"模型评估：\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型及模型参数：\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "模型评估：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.93      1.00      0.97        14\n",
      "          2       1.00      0.88      0.93        16\n",
      "          3       0.86      1.00      0.92         6\n",
      "\n",
      "avg / total       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "cls=XGBClassifier()\n",
    "cls.fit(X_train,y_train)\n",
    "y_pred=cls.predict(X_test)\n",
    "\n",
    "print(\"模型及模型参数：\")   \n",
    "print(str(cls))\n",
    "print(\"模型评估：\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、特征工程（特征选择+降维）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
